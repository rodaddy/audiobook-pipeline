---
phase: 04-automation-triggers
plan: 02
type: execute
wave: 2
depends_on: [04-01]
files_modified:
  - bin/audiobook-convert
  - lib/concurrency.sh
  - stages/01-validate.sh
  - config.env.example
autonomous: true

must_haves:
  truths:
    - Second pipeline instance exits cleanly (exit 0) when lock held
    - Lock is automatically released on normal exit, error exit, and abnormal termination
    - Pipeline refuses to start if disk space is less than 3x source size
    - Insufficient disk space logged as clear error (not crash)
  artifacts:
    - path: lib/concurrency.sh
      provides: flock-based global singleton lock
      exports: [acquire_global_lock]
      min_lines: 30
    - path: bin/audiobook-convert
      provides: Lock acquisition before pipeline starts
      pattern: "acquire_global_lock"
    - path: stages/01-validate.sh
      provides: Disk space pre-flight check
      pattern: "check_disk_space"
  key_links:
    - from: bin/audiobook-convert
      to: lib/concurrency.sh
      via: source statement and acquire_global_lock call
      pattern: "source.*concurrency\\.sh.*acquire_global_lock"
    - from: stages/01-validate.sh
      to: lib/concurrency.sh
      via: check_disk_space function call
      pattern: "check_disk_space.*SOURCE_PATH.*WORK_DIR"
---

<objective>
Add flock-based concurrency control and disk space pre-flight checks to prevent pipeline collisions and out-of-space failures.

Purpose: Ensures singleton behavior (only one pipeline instance runs at a time) and prevents conversion attempts when insufficient disk space. Both requirements critical for automated hook/cron triggers.

Output: Global lock integration in main binary, disk space checks in validate stage, helper library for concurrency control.
</objective>

<execution_context>
@/Users/rico/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rico/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-automation-triggers/04-RESEARCH.md
@bin/audiobook-convert
@lib/core.sh
@stages/01-validate.sh
@config.env.example
</context>

<tasks>

<task type="auto">
  <name>Create lib/concurrency.sh with flock global lock and disk space check</name>
  <files>lib/concurrency.sh</files>
  <action>
Create new library file with two functions:

**1. acquire_global_lock():**
- Use flock with FD 200 on $LOCK_DIR/pipeline.lock
- Non-blocking (-n) with exit code 0 on failure (-E 0)
- If lock acquisition fails: log_info "Another pipeline instance is running. Exiting cleanly." and exit 0
- Lock automatically released when FD 200 closes (script exit)
- Return 0 on success

**2. check_disk_space():**
- Args: SOURCE_DIR WORK_DIR
- Calculate source size with: `du -sk "$source_dir" | awk '{print $1}'`
- Calculate required space: 3x source size in KB
- Get available space: `df -k "$work_dir" | awk 'NR==2 {print $4}'`
- Log structured message: "Disk space check: source=${source_size_kb}KB required=${required_kb}KB available=${available_kb}KB"
- Return 1 if insufficient, log_error with clear message
- Return 0 if sufficient

Use #!/usr/bin/env bash shebang, set -euo pipefail, source lib/core.sh for logging.

Defaults: LOCK_DIR="${LOCK_DIR:-/var/lib/audiobook-pipeline/locks}"

Reference research section 4 (lines 171-218) and section 5 (lines 220-258) for exact patterns.
  </action>
  <verify>
bash -n lib/concurrency.sh (syntax check)
grep -q "flock -n -E 0 200" lib/concurrency.sh
grep -q "check_disk_space()" lib/concurrency.sh
  </verify>
  <done>
lib/concurrency.sh exists with acquire_global_lock and check_disk_space functions following research patterns
  </done>
</task>

<task type="auto">
  <name>Integrate global lock into bin/audiobook-convert</name>
  <files>bin/audiobook-convert</files>
  <action>
Add concurrency control to main pipeline before stage execution:

**1. Source lib/concurrency.sh:**
- Add after line 128 (after lib/archive.sh source): `source "$LIB_DIR/concurrency.sh"`

**2. Acquire global lock in main() function:**
- Insert after line 189 (before "PIPELINE_START=$(date +%s)")
- Call: `acquire_global_lock` (no args, function handles exit 0 on contention)
- Add log_info "Global lock acquired. Starting pipeline." after successful return

**3. Export LOCK_DIR config variable:**
- Add to config defaults section (after line 102, with other exports)
- Default: `LOCK_DIR="${LOCK_DIR:-/var/lib/audiobook-pipeline/locks}"`
- Export: `export LOCK_DIR`

Lock automatically released when script exits (normal, error trap, or signal). No explicit unlock needed.

Reference research section 4 (lines 171-189) for integration pattern.
  </action>
  <verify>
bash -n bin/audiobook-convert
grep -q "source.*concurrency.sh" bin/audiobook-convert
grep -q "acquire_global_lock" bin/audiobook-convert
grep -q "LOCK_DIR=" bin/audiobook-convert
  </verify>
  <done>
bin/audiobook-convert sources lib/concurrency.sh and calls acquire_global_lock before pipeline starts; LOCK_DIR configured
  </done>
</task>

<task type="auto">
  <name>Add disk space pre-flight check to validate stage</name>
  <files>stages/01-validate.sh</files>
  <action>
Add disk space check to stage_validate() after source directory verification:

**1. Source lib/concurrency.sh:**
- Add after line 12 (after source lib/manifest.sh): `source "$SCRIPT_DIR/lib/concurrency.sh"`

**2. Call check_disk_space:**
- Insert after line 25 (after source directory existence check)
- Pattern:
```bash
# Pre-flight disk space check (NFR-04)
if ! check_disk_space "$SOURCE_PATH" "$WORK_DIR"; then
  die "Insufficient disk space to process $SOURCE_PATH (need 3x source size)"
fi
```

**Why in validate stage:** Fail fast before any processing starts. Disk space checked once per book at pipeline entry.

**Exit behavior on failure:** check_disk_space returns 1, die() logs error and exits 1 (permanent failure, no retry).

Reference research section 5 (lines 220-258) for check_disk_space implementation details.
  </action>
  <verify>
bash -n stages/01-validate.sh
grep -q "source.*concurrency.sh" stages/01-validate.sh
grep -q "check_disk_space" stages/01-validate.sh
  </verify>
  <done>
stages/01-validate.sh calls check_disk_space before MP3 validation; fails cleanly if insufficient space
  </done>
</task>

</tasks>

<verification>
**Concurrency control:**
1. Start first pipeline instance in background: `bin/audiobook-convert /path/to/book &`
2. Start second instance immediately: `bin/audiobook-convert /path/to/book`
3. Second instance should log "Another pipeline instance is running" and exit 0 (not error)
4. After first completes, third instance should acquire lock and proceed

**Disk space check:**
1. Create small test directory (< 1MB)
2. Set WORK_DIR to nearly-full filesystem (or mock df output)
3. Run: `bin/audiobook-convert /path/to/small-book`
4. Should fail in validate stage with "Insufficient disk space" error message
5. Verify log shows source/required/available KB values

**Lock cleanup:**
1. Kill pipeline with SIGTERM mid-run: `kill -TERM $PID`
2. Verify lock file released (next instance acquires successfully)
3. Lock file exists at /var/lib/audiobook-pipeline/locks/pipeline.lock but FD released
</verification>

<success_criteria>
- [ ] lib/concurrency.sh created with acquire_global_lock and check_disk_space functions
- [ ] bin/audiobook-convert sources concurrency.sh and calls acquire_global_lock before pipeline starts
- [ ] Second pipeline instance exits cleanly (exit 0) when first instance holds lock
- [ ] stages/01-validate.sh calls check_disk_space before MP3 validation
- [ ] Pipeline refuses to start when disk space < 3x source size
- [ ] Error messages include actual KB values for debugging
- [ ] Lock automatically released on normal exit, error trap, and signal termination
- [ ] All bash syntax valid (bash -n passes for all modified files)
</success_criteria>

<output>
After completion, create `.planning/phases/04-automation-triggers/04-02-SUMMARY.md` with:
- Functions created (acquire_global_lock, check_disk_space signatures)
- Integration points (where lock acquired, where disk checked)
- Lock file location and FD number used
- Disk space multiplier (3x) and calculation method
- Exit codes (0 on lock contention, 1 on disk space failure)
- Testing notes (how to verify concurrent behavior)
</output>
