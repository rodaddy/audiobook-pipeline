---
phase: 04-automation-triggers
plan: 03
type: execute
wave: 3
depends_on: [04-01, 04-02]
files_modified: [lib/core.sh, lib/manifest.sh, lib/error-recovery.sh, bin/audiobook-convert, config.env.example, logrotate.d/audiobook-pipeline]
autonomous: true

must_haves:
  truths:
    - Failed books retry up to 3 times before moving to failed/ directory
    - Permanent failures (corrupt input, config errors) move to failed/ immediately
    - Failed books preserve error context in ERROR.txt and manifest copy
    - Retry count tracked in manifest for each processing attempt
    - Automation cycle provides natural retry without in-process delays
    - Optional webhook notification fires on permanent/retry-exhausted failures
    - Log rotation prevents unbounded log file growth
  artifacts:
    - path: lib/manifest.sh
      provides: Extended manifest schema with retry_count, max_retries, last_error fields
      contains: "retry_count"
      min_lines: 160
    - path: lib/error-recovery.sh
      provides: Move-to-failed and failure notification logic
      exports: [move_to_failed, send_failure_notification]
      min_lines: 80
    - path: bin/audiobook-convert
      provides: Enhanced error trap with retry/failure categorization
      contains: "exit_code categorization"
      min_lines: 300
    - path: config.env.example
      provides: Configuration for retry limits, failed directory, webhook URLs
      contains: "MAX_RETRIES"
    - path: logrotate.d/audiobook-pipeline
      provides: Log rotation config (daily, 14-day retention, compress)
      min_lines: 10
  key_links:
    - from: bin/audiobook-convert
      to: lib/error-recovery.sh
      via: move_to_failed function call
      pattern: "move_to_failed.*BOOK_HASH"
    - from: lib/error-recovery.sh
      to: lib/manifest.sh
      via: manifest_read for error context
      pattern: "manifest_read.*last_error"
    - from: bin/audiobook-convert
      to: lib/manifest.sh
      via: retry_count increment on error
      pattern: "retry_count.*\\+="
---

<objective>
Implement structured error recovery with retry logic, failure categorization, and failed book handling.

Purpose: Ensure failed books don't block the queue -- retry transient failures up to 3 times, move permanent failures to failed/ directory immediately, preserve error context for debugging.

Output: Robust error recovery system with automatic retries, failure isolation, and optional notifications.
</objective>

<execution_context>
@/Users/rico/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rico/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-automation-triggers/04-RESEARCH.md
@bin/audiobook-convert
@lib/core.sh
@lib/manifest.sh
@config.env.example
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend manifest schema with retry tracking</name>
  <files>lib/manifest.sh</files>
  <action>
Add retry tracking fields to manifest schema:

1. In `manifest_create()` function (line 19), extend the jq-generated JSON structure to include:
   - `retry_count: 0` (number of retry attempts so far)
   - `max_retries: 3` (maximum retries before moving to failed/)
   - `last_error: {}` (empty object, populated on failure)

2. Add convenience function `manifest_increment_retry()`:
   ```bash
   manifest_increment_retry() {
     local book_hash="$1"
     manifest_update "$book_hash" '.retry_count += 1'
     log_debug "Retry count incremented for $book_hash"
   }
   ```

3. Add function `manifest_set_error()`:
   ```bash
   manifest_set_error() {
     local book_hash="$1"
     local stage="$2"
     local exit_code="$3"
     local category="$4"  # "transient" or "permanent"
     local message="$5"

     local timestamp
     timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)

     manifest_update "$book_hash" \
       ".last_error.timestamp = \"$timestamp\"
        | .last_error.stage = \"$stage\"
        | .last_error.exit_code = $exit_code
        | .last_error.category = \"$category\"
        | .last_error.message = \"$message\""

     log_error "Error recorded: stage=$stage exit=$exit_code category=$category"
   }
   ```

4. NO changes to existing functions -- these are additions only.

Implementation notes:
- Maintain existing atomic write pattern (tmpfile + mv)
- Use existing jq filter format from manifest_update
- Log at DEBUG level for retry increments (noisy), ERROR for error records
  </action>
  <verify>
1. Verify manifest_create generates correct JSON:
   ```bash
   source lib/core.sh
   source lib/manifest.sh
   MANIFEST_DIR=/tmp/test-manifests
   mkdir -p "$MANIFEST_DIR"
   manifest_create "test123" "/tmp/test-source"
   jq . /tmp/test-manifests/test123.json
   ```
   Output should include: `retry_count: 0`, `max_retries: 3`, `last_error: {}`

2. Verify retry increment works:
   ```bash
   manifest_increment_retry "test123"
   jq '.retry_count' /tmp/test-manifests/test123.json
   ```
   Output: `1`

3. Verify error recording works:
   ```bash
   manifest_set_error "test123" "convert" 1 "transient" "ffmpeg timeout"
   jq '.last_error' /tmp/test-manifests/test123.json
   ```
   Output includes stage, exit_code, category, message, timestamp
  </verify>
  <done>
Manifest schema includes retry_count, max_retries, and last_error fields. Convenience functions manifest_increment_retry() and manifest_set_error() exist and work correctly.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create error recovery module</name>
  <files>lib/error-recovery.sh</files>
  <action>
Create new file `lib/error-recovery.sh` with two functions:

**1. move_to_failed function:**
```bash
#!/usr/bin/env bash
# lib/error-recovery.sh -- Failed book handling and notifications
# Sourced by bin/audiobook-convert; do not execute directly.
# Requires: lib/core.sh, lib/manifest.sh sourced first

# Move failed book to failed/ directory with error context
# Args: BOOK_HASH SOURCE_PATH
move_to_failed() {
  local book_hash="$1"
  local source_path="$2"
  local failed_dir="${FAILED_DIR:-/var/lib/audiobook-pipeline/failed}"

  mkdir -p "$failed_dir"

  local book_name
  book_name=$(basename "$source_path")
  local failed_path="$failed_dir/$book_name"

  # Avoid clobbering if name collision
  local counter=1
  while [[ -e "$failed_path" ]]; do
    failed_path="$failed_dir/${book_name}.${counter}"
    counter=$((counter + 1))
  done

  log_error "Moving failed book to: $failed_path"

  if [[ "${DRY_RUN:-false}" != "true" ]]; then
    mv "$source_path" "$failed_path"

    # Copy manifest for debugging context
    local manifest
    manifest=$(manifest_path "$book_hash")
    if [[ -f "$manifest" ]]; then
      cp "$manifest" "$failed_path/pipeline-manifest.json"
    fi

    # Write human-readable error summary
    local retry_count
    retry_count=$(manifest_read "$book_hash" "retry_count" || echo "0")
    local error_stage
    error_stage=$(manifest_read "$book_hash" "last_error.stage" || echo "unknown")
    local error_timestamp
    error_timestamp=$(manifest_read "$book_hash" "last_error.timestamp" || echo "unknown")
    local error_exit_code
    error_exit_code=$(manifest_read "$book_hash" "last_error.exit_code" || echo "unknown")
    local error_category
    error_category=$(manifest_read "$book_hash" "last_error.category" || echo "unknown")
    local error_message
    error_message=$(manifest_read "$book_hash" "last_error.message" || echo "unknown")

    cat > "$failed_path/ERROR.txt" <<EOF
Pipeline failed after $retry_count attempts.

Last error:
  Stage: $error_stage
  Time: $error_timestamp
  Exit code: $error_exit_code
  Category: $error_category
  Message: $error_message

Work directory: ${WORK_DIR:-unknown}
Manifest: pipeline-manifest.json
EOF
  fi

  log_info "Failed book moved to $failed_path"
}
```

**2. send_failure_notification function:**
```bash
# Send webhook notification for permanent or retry-exhausted failures
# Args: BOOK_HASH STAGE MESSAGE
send_failure_notification() {
  local book_hash="$1"
  local stage="$2"
  local message="$3"

  local webhook_url="${FAILURE_WEBHOOK_URL:-}"
  [[ -z "$webhook_url" ]] && return 0  # Skip if not configured

  local book_name
  book_name=$(manifest_read "$book_hash" "source_path" | xargs basename)

  local payload
  payload=$(jq -n \
    --arg text "Audiobook pipeline failure: $book_name" \
    --arg stage "$stage" \
    --arg msg "$message" \
    --arg hash "$book_hash" \
    '{
      text: $text,
      fields: [
        { title: "Book", value: $hash, short: true },
        { title: "Stage", value: $stage, short: true },
        { title: "Error", value: $msg }
      ]
    }')

  # Non-blocking: short timeout, ignore failures
  curl -s -m 5 -X POST -H 'Content-Type: application/json' \
    --data "$payload" "$webhook_url" >/dev/null 2>&1 || true

  log_debug "Failure notification sent to webhook"
}
```

Implementation notes:
- Use `set -euo pipefail` at top of file
- Both functions depend on global vars from config.env (FAILED_DIR, FAILURE_WEBHOOK_URL)
- DRY_RUN aware -- move_to_failed logs intent but doesn't move
- Webhook failures are silent (|| true) -- never block pipeline
- Name collision handling prevents overwriting existing failed books
  </action>
  <verify>
1. Verify move_to_failed creates correct structure:
   ```bash
   source lib/core.sh
   source lib/manifest.sh
   source lib/error-recovery.sh
   FAILED_DIR=/tmp/test-failed
   mkdir -p /tmp/test-source
   echo "test" > /tmp/test-source/file.mp3
   manifest_create "test123" "/tmp/test-source"
   manifest_set_error "test123" "convert" 3 "permanent" "corrupt input"
   move_to_failed "test123" "/tmp/test-source"
   ls -la /tmp/test-failed/test-source/
   cat /tmp/test-failed/test-source/ERROR.txt
   ```
   Verify: Source moved, ERROR.txt exists, pipeline-manifest.json exists

2. Verify send_failure_notification handles missing webhook gracefully:
   ```bash
   FAILURE_WEBHOOK_URL=""
   send_failure_notification "test123" "convert" "test error"
   echo $?
   ```
   Output: 0 (success, skipped silently)

3. Verify dry-run mode doesn't move files:
   ```bash
   DRY_RUN=true
   mkdir -p /tmp/test-source2
   move_to_failed "test456" "/tmp/test-source2"
   [[ -d /tmp/test-source2 ]] && echo "PASS: dry-run preserved source"
   ```
  </verify>
  <done>
lib/error-recovery.sh exists with move_to_failed and send_failure_notification functions. Both functions handle edge cases correctly (missing manifest, webhook, name collisions, dry-run).
  </done>
</task>

<task type="auto">
  <name>Task 3: Enhance error trap with retry logic</name>
  <files>bin/audiobook-convert, config.env.example</files>
  <action>
**1. Update bin/audiobook-convert:**

Source the new error recovery module after other libs (around line 128):
```bash
# shellcheck disable=SC1091
source "$LIB_DIR/error-recovery.sh"
```

Find and replace the on_error() function (locate via `grep -n 'on_error()' bin/audiobook-convert` -- do NOT use hardcoded line numbers as earlier plans modify this file) with enhanced version:

```bash
# Error trap -- categorizes failure, handles retries, moves to failed/ if needed
on_error() {
  local lineno="$1"
  local exit_code=$?

  log_error "Pipeline failed at line $lineno (exit=$exit_code)"

  if [[ -z "$CURRENT_STAGE" || -z "${BOOK_HASH:-}" ]]; then
    log_error "No stage or book_hash set, cannot update manifest"
    return 0
  fi

  # Categorize failure based on exit code
  local category="transient"
  case $exit_code in
    2|3)
      category="permanent"
      log_error "Permanent failure detected (exit=$exit_code)"
      ;;
    *)
      category="transient"
      log_warn "Transient failure detected (exit=$exit_code)"
      ;;
  esac

  # Update manifest with error details
  if [[ -f "$(manifest_path "$BOOK_HASH")" ]]; then
    manifest_set_stage "$BOOK_HASH" "$CURRENT_STAGE" "failed" || true
    manifest_set_error "$BOOK_HASH" "$CURRENT_STAGE" "$exit_code" "$category" "Pipeline failed at line $lineno" || true
    manifest_increment_retry "$BOOK_HASH" || true
    manifest_update "$BOOK_HASH" '.status = "failed"' || true
  fi

  # Handle permanent failures immediately
  if [[ "$category" == "permanent" ]]; then
    log_error "Permanent failure -- moving to failed/ directory"
    send_failure_notification "$BOOK_HASH" "$CURRENT_STAGE" "Permanent failure at line $lineno"
    move_to_failed "$BOOK_HASH" "$SOURCE_PATH"
    exit $exit_code
  fi

  # Check retry limit for transient failures
  local retry_count
  retry_count=$(manifest_read "$BOOK_HASH" "retry_count" || echo "0")
  local max_retries="${MAX_RETRIES:-3}"

  if [[ "$retry_count" -ge "$max_retries" ]]; then
    log_error "Max retries ($max_retries) exceeded -- moving to failed/"
    send_failure_notification "$BOOK_HASH" "$CURRENT_STAGE" "Max retries exceeded after $retry_count attempts"
    move_to_failed "$BOOK_HASH" "$SOURCE_PATH"
    exit 1
  fi

  log_info "Work directory preserved for debugging: ${WORK_DIR:-unknown}"
  log_info "Will retry on next automation cycle (attempt $retry_count/$max_retries)"
}
```

**2. Update config.env.example:**

Add new section after ARCHIVE config (around line 47):

```bash
# Error recovery and retry (Phase 4)
MAX_RETRIES=3                                    # Number of retry attempts before moving to failed/
FAILED_DIR="/var/lib/audiobook-pipeline/failed" # Permanent and retry-exhausted failures
FAILURE_WEBHOOK_URL=""                           # Optional Slack/Discord webhook for notifications
FAILURE_EMAIL=""                                 # Optional email for notifications (future)
```

Implementation notes:
- Exit code 2 = config errors (missing API key, invalid paths)
- Exit code 3 = corrupt input (unreadable MP3, invalid audio format)
- Exit codes 1, 4+ = transient (network failures, API timeouts, temp resource exhaustion)
- Retry count increments BEFORE checking max_retries (first failure = retry_count 1)
- Work directory preserved on transient failures for debugging
- All manifest operations wrapped in `|| true` to prevent error trap recursion
  </action>
  <verify>
1. Verify permanent failure handling:
   ```bash
   # Create test book that will fail with exit 3
   mkdir -p /tmp/corrupt-book
   echo "not an mp3" > /tmp/corrupt-book/file.mp3
   ./bin/audiobook-convert /tmp/corrupt-book
   # Expect: Immediate move to failed/, no retry
   ls /var/lib/audiobook-pipeline/failed/
   ```

2. Verify retry limit handling:
   ```bash
   # Manually set retry_count to 3 in manifest
   BOOK_HASH=$(echo -n "/tmp/test-book" | sha256sum | cut -d' ' -f1 | head -c 12)
   manifest_create "$BOOK_HASH" "/tmp/test-book"
   manifest_update "$BOOK_HASH" '.retry_count = 3'
   # Trigger failure (exit 1 = transient)
   CURRENT_STAGE=convert
   SOURCE_PATH=/tmp/test-book
   bash -c 'set -e; source lib/core.sh; source lib/manifest.sh; source lib/error-recovery.sh; exit 1'
   # Expect: Move to failed/, "Max retries exceeded" log message
   ```

3. Verify transient failure preserves work directory:
   ```bash
   # Set retry_count = 0, trigger exit 1
   manifest_update "$BOOK_HASH" '.retry_count = 0'
   # Expect: "Will retry on next automation cycle (attempt 1/3)" log message
   # Work directory still exists
   ```
  </verify>
  <done>
Error trap categorizes failures correctly (exit 2-3 = permanent, others = transient). Permanent failures move to failed/ immediately. Transient failures retry up to MAX_RETRIES times. Retry count tracked in manifest. Work directory preserved for debugging on transient failures.
  </done>
</task>

<task type="auto">
  <name>Task 4: Add logrotate configuration</name>
  <files>logrotate.d/audiobook-pipeline</files>
  <action>
Create new directory `logrotate.d/` in project root, then create `logrotate.d/audiobook-pipeline` file:

```
/var/log/audiobook-pipeline/*.log {
    daily
    rotate 14
    copytruncate
    compress
    delaycompress
    notifempty
    missingok
    dateext
    dateformat -%Y%m%d
    su readarr media
}
```

Configuration explanation:
- `daily` -- rotate once per day
- `rotate 14` -- keep 14 days of rotated logs (2 weeks)
- `copytruncate` -- copy log file, then truncate (no process restart needed)
- `compress` -- gzip rotated logs to save space
- `delaycompress` -- delay compression by 1 cycle (allows active log to remain uncompressed)
- `notifempty` -- skip rotation if log file is empty
- `missingok` -- don't error if log file doesn't exist
- `dateext` -- append date to rotated log filename (e.g., convert.log-20260220)
- `dateformat -%Y%m%d` -- YYYYMMDD format
- `su readarr media` -- run rotation as readarr user with media group (matches pipeline user)

Also create `logrotate.d/README.md`:

```markdown
# Logrotate Configuration

Install this configuration to `/etc/logrotate.d/` on the system running the audiobook pipeline:

\`\`\`bash
sudo cp logrotate.d/audiobook-pipeline /etc/logrotate.d/audiobook-pipeline
sudo chmod 644 /etc/logrotate.d/audiobook-pipeline
\`\`\`

Test the configuration:

\`\`\`bash
sudo logrotate -d /etc/logrotate.d/audiobook-pipeline  # dry-run
sudo logrotate -f /etc/logrotate.d/audiobook-pipeline  # force rotation
\`\`\`

Logs are rotated daily and kept for 14 days. Rotated logs are compressed (gzip) to save space.
```

Implementation notes:
- `copytruncate` prevents brief log loss window (acceptable vs restarting pipeline)
- No `create` directive -- lib/core.sh creates log file on first write
- `su readarr media` matches FILE_OWNER config (UID 2018, GID 2000)
- logrotate runs daily via cron.daily, no separate cron entry needed
  </action>
  <verify>
1. Verify logrotate config syntax:
   ```bash
   sudo logrotate -d logrotate.d/audiobook-pipeline
   ```
   Expected: No errors, shows rotation plan

2. Verify copytruncate behavior (simulate):
   ```bash
   mkdir -p /var/log/audiobook-pipeline
   echo "test log line" >> /var/log/audiobook-pipeline/convert.log
   sudo logrotate -f logrotate.d/audiobook-pipeline
   ls -lh /var/log/audiobook-pipeline/
   ```
   Expected: convert.log (truncated), convert.log-YYYYMMDD.gz (compressed)

3. Verify file permissions after rotation:
   ```bash
   stat /var/log/audiobook-pipeline/convert.log-*
   ```
   Expected: Owner = readarr (2018), Group = media (2000)
  </verify>
  <done>
Logrotate configuration exists at logrotate.d/audiobook-pipeline with daily rotation, 14-day retention, compression, and correct user/group. README.md provides installation instructions.
  </done>
</task>

</tasks>

<verification>
**Overall Phase 04 Plan 03 Checks:**

1. **Manifest retry tracking:**
   - Create a book manifest, increment retry_count, verify field updates
   - Record an error, verify last_error object populated with all fields

2. **Error categorization:**
   - Trigger exit code 3 (permanent), verify immediate move to failed/
   - Trigger exit code 1 (transient) with retry_count < max, verify retry scheduled
   - Trigger exit code 1 with retry_count = max_retries, verify move to failed/

3. **Failed book handling:**
   - Move a book to failed/, verify ERROR.txt exists with correct content
   - Verify manifest copied as pipeline-manifest.json
   - Verify name collision handling (multiple books with same name)

4. **Webhook notifications:**
   - Set FAILURE_WEBHOOK_URL, trigger permanent failure, verify curl invoked
   - Unset FAILURE_WEBHOOK_URL, trigger failure, verify no curl call
   - Simulate webhook timeout, verify pipeline continues (|| true works)

5. **Log rotation:**
   - Run logrotate in dry-run mode, verify config parses correctly
   - Force rotation, verify old log compressed and new log truncated
   - Verify rotated logs have correct ownership (readarr:media)

6. **Integration with automation:**
   - Failed book in _incoming/ directory
   - Cron scanner creates trigger file
   - Queue processor runs pipeline
   - Pipeline fails (transient), retry_count = 1
   - Next cron cycle re-triggers same book
   - Pipeline fails again, retry_count = 2
   - Third failure moves to failed/
   - Verify failed/ book has ERROR.txt with retry_count = 3
</verification>

<success_criteria>
1. Extended manifest schema includes retry_count (default 0), max_retries (default 3), and last_error object
2. lib/error-recovery.sh exists with move_to_failed and send_failure_notification functions
3. Enhanced error trap in bin/audiobook-convert categorizes failures as permanent (exit 2-3) or transient (exit 1, 4+)
4. Permanent failures move to failed/ directory immediately without retry
5. Transient failures increment retry_count and exit cleanly for next automation cycle
6. When retry_count >= max_retries, book moves to failed/ directory
7. Failed books preserve ERROR.txt (human-readable) and pipeline-manifest.json (machine-readable) in failed/ directory
8. Optional webhook notification fires for permanent failures and retry-exhausted failures
9. Logrotate configuration rotates logs daily, keeps 14 days, compresses with gzip
10. Work directories preserved on transient failures for debugging
11. All error recovery operations are DRY_RUN aware
12. Failed book directory structure prevents name collisions (appends .1, .2, etc.)
</success_criteria>

<output>
After completion, create `.planning/phases/04-automation-triggers/04-03-SUMMARY.md` using the summary template.
</output>
