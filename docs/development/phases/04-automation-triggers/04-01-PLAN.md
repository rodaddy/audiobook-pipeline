---
phase: 04-automation-triggers
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - bin/readarr-hook.sh
  - bin/cron-scanner.sh
  - bin/queue-processor.sh
  - config.env.example
autonomous: true

must_haves:
  truths:
    - "Readarr OnReleaseImport webhook triggers pipeline without blocking (exits <5s)"
    - "Cron scanner detects books missed by webhook (fallback mechanism)"
    - "Queue processor handles trigger files asynchronously without race conditions"
    - "Multiple trigger sources (webhook + cron) can coexist safely"
    - "Incomplete downloads are not processed (mtime stability check)"
  artifacts:
    - path: "bin/readarr-hook.sh"
      provides: "Fast-exit webhook script for Readarr integration"
      exports: ["creates JSON trigger files in queue dir"]
      min_lines: 60
    - path: "bin/cron-scanner.sh"
      provides: "Cron-triggered fallback scanner with stability checks"
      exports: ["creates JSON trigger files for detected books"]
      min_lines: 80
    - path: "bin/queue-processor.sh"
      provides: "Asynchronous trigger file processor invoking bin/audiobook-convert"
      exports: ["processes trigger files, moves to completed/failed"]
      min_lines: 70
    - path: "config.env.example"
      provides: "Configuration variables for automation"
      contains: "QUEUE_DIR"
  key_links:
    - from: "bin/readarr-hook.sh"
      to: "queue dir"
      via: "writes JSON trigger file"
      pattern: "cat.*TRIGGER_FILE"
    - from: "bin/cron-scanner.sh"
      to: "queue dir"
      via: "writes JSON trigger file"
      pattern: "cat.*trigger_file"
    - from: "bin/queue-processor.sh"
      to: "bin/audiobook-convert"
      via: "executes pipeline for each queued book"
      pattern: "\\$PIPELINE_BIN.*\\$book_path"
    - from: "bin/cron-scanner.sh"
      to: "MANIFEST_DIR"
      via: "checks if already processed"
      pattern: "\\$MANIFEST_DIR.*\\.json"
---

<objective>
Create Readarr webhook integration and cron-based fallback scanner to automatically trigger the audiobook conversion pipeline when new books arrive.

Purpose: Eliminate manual CLI invocation (FR-TRIG-01, FR-TRIG-02). Enable fully automated pipeline workflow from download to processing.

Output: Three automation scripts (Readarr hook, cron scanner, queue processor) and updated config with automation directories.
</objective>

<execution_context>
@/Users/rico/.claude/get-shit-done/workflows/execute-plan.md
@/Users/rico/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-automation-triggers/04-RESEARCH.md
@bin/audiobook-convert
@lib/core.sh
@lib/manifest.sh
@config.env.example
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Readarr fast-exit hook script</name>
  <files>bin/readarr-hook.sh</files>
  <action>
Create `bin/readarr-hook.sh` using fast-exit pattern from research (04-RESEARCH.md section 2). Script must:

1. Exit immediately (exit 0) for Test events (`readarr_eventtype == "Test"`)
2. Validate required env var `readarr_addedbookpaths` exists (exit 1 if missing)
3. Generate unique trigger filename: `YYYYMMDD-HHMMSS-{6-char-random}.json`
4. Write JSON payload to `QUEUE_DIR` with fields:
   - timestamp (RFC-3339 format)
   - event_type (from `readarr_eventtype`)
   - book_paths (from `readarr_addedbookpaths` -- pipe-separated value preserved)
   - book_id, book_title, author_name, asin (from respective env vars, default to empty)
5. Exit 0 (fast exit target: <5 seconds)

Use `#!/usr/bin/env bash` shebang (LAW 7). Set `set -euo pipefail`. Source config from `../config.env` to get `QUEUE_DIR` (default fallback: `/var/lib/audiobook-pipeline/queue`). Create queue dir if missing (`mkdir -p`).

DO NOT invoke bin/audiobook-convert from the hook -- that's the queue processor's job (separation of concerns for fast exit).
  </action>
  <verify>
Test script behavior:
```bash
# Test event (should exit 0 immediately)
readarr_eventtype=Test bin/readarr-hook.sh
echo "Exit code: $?"  # Should be 0

# Missing required var (should exit 1)
readarr_eventtype=Download bin/readarr-hook.sh
echo "Exit code: $?"  # Should be 1

# Valid trigger (should create file)
export readarr_eventtype=Download
export readarr_addedbookpaths="/mnt/media/AudioBooks/_incoming/Test Book"
export readarr_book_title="Test Book"
export readarr_author_name="Test Author"
bin/readarr-hook.sh
ls /var/lib/audiobook-pipeline/queue/*.json  # Should show new file
cat /var/lib/audiobook-pipeline/queue/*.json  # Verify JSON format
```
  </verify>
  <done>bin/readarr-hook.sh creates valid JSON trigger files in queue dir, exits within 5 seconds, handles Test events and missing env vars correctly</done>
</task>

<task type="auto">
  <name>Task 2: Create cron fallback scanner with stability check</name>
  <files>bin/cron-scanner.sh</files>
  <action>
Create `bin/cron-scanner.sh` using fallback scanner pattern from research (04-RESEARCH.md section 3). Script must:

1. Source config from `../config.env` to get `INCOMING_DIR`, `QUEUE_DIR`, `MANIFEST_DIR`
2. Defaults: `INCOMING_DIR=/mnt/media/AudioBooks/_incoming`, `STABILITY_THRESHOLD=120` (2 minutes)
3. Find all top-level directories in `INCOMING_DIR` (maxdepth 1)
4. For each directory:
   - Generate book_hash using same method as bin/audiobook-convert (SHA-256 of directory path, truncate to 12 chars)
   - Skip if manifest already exists (`$MANIFEST_DIR/$book_hash.json`)
   - Skip if trigger file already queued (grep book_paths in existing queue/*.json files)
   - Stability check: Find newest file mtime in directory, verify age >= STABILITY_THRESHOLD seconds
   - If stable: Create trigger file `$QUEUE_DIR/YYYYMMDD-HHMMSS-{book_hash}.json` with:
     - timestamp (RFC-3339)
     - event_type: "CronScan"
     - book_paths: directory path
     - source: "cron-scanner"
5. Use `set -euo pipefail`, `#!/usr/bin/env bash`

Stability check implementation: Use `find "$book_dir" -type f -printf '%T@ %p\n' | sort -rn | head -n1` to get newest file mtime as epoch timestamp, compare to `date +%s`.

Book hash generation: Must match bin/audiobook-convert logic. Use `echo -n "$book_dir" | sha256sum | cut -d' ' -f1 | head -c 12`.
  </action>
  <verify>
Test scanner behavior:
```bash
# Create test incoming directory
mkdir -p /tmp/test-incoming/stable-book
touch -d "5 minutes ago" /tmp/test-incoming/stable-book/file.mp3

# Run scanner with test config
INCOMING_DIR=/tmp/test-incoming bin/cron-scanner.sh

# Verify trigger created
ls /var/lib/audiobook-pipeline/queue/*.json
cat /var/lib/audiobook-pipeline/queue/*.json | jq .event_type  # Should be "CronScan"

# Create fresh book (should NOT trigger)
mkdir -p /tmp/test-incoming/new-book
touch /tmp/test-incoming/new-book/file.mp3
INCOMING_DIR=/tmp/test-incoming bin/cron-scanner.sh
# Should NOT create a second trigger for new-book
```
  </verify>
  <done>bin/cron-scanner.sh creates trigger files only for stable books (mtime >= 2 minutes), skips already-processed books, avoids duplicate triggers</done>
</task>

<task type="auto">
  <name>Task 3: Create queue processor and update config</name>
  <files>bin/queue-processor.sh, config.env.example</files>
  <action>
**Part A: Create bin/queue-processor.sh** using queue processor pattern from research (04-RESEARCH.md section 3). Script must:

1. Source config from `../config.env` to get `QUEUE_DIR`, `PROCESSING_DIR`, `COMPLETED_DIR`, `FAILED_DIR`, `PIPELINE_BIN`
2. Defaults:
   - `QUEUE_DIR=/var/lib/audiobook-pipeline/queue`
   - `PROCESSING_DIR=/var/lib/audiobook-pipeline/processing`
   - `COMPLETED_DIR=/var/lib/audiobook-pipeline/completed`
   - `FAILED_DIR=/var/lib/audiobook-pipeline/failed`
   - `PIPELINE_BIN=/opt/audiobook-pipeline/bin/audiobook-convert`
3. Loop through `$QUEUE_DIR/*.json` files
4. For each trigger file:
   - Atomic claim: `mv "$trigger_file" "$PROCESSING_DIR/$(basename "$trigger_file").lock"` (prevents concurrent processing)
   - Skip if mv fails (another processor claimed it)
   - Parse JSON using jq: extract `book_paths` field
   - Handle pipe-separated paths: `IFS='|' read -ra PATHS <<< "$book_paths"`
   - For each path:
     - Skip if directory doesn't exist
     - Invoke `"$PIPELINE_BIN" "$book_path"` (blocking call)
     - If exit 0: `mv "$lock_file" "$COMPLETED_DIR/$(basename "$lock_file" .lock)"`
     - If exit non-zero: `mv "$lock_file" "$FAILED_DIR/$(basename "$lock_file" .lock)"`
5. Use `set -euo pipefail`, `#!/usr/bin/env bash`

Create processing/completed/failed directories via `mkdir -p` at script start.

**Part B: Update config.env.example** to add automation config section:
```bash
# Automation (Phase 4)
QUEUE_DIR="/var/lib/audiobook-pipeline/queue"
PROCESSING_DIR="/var/lib/audiobook-pipeline/processing"
COMPLETED_DIR="/var/lib/audiobook-pipeline/completed"
FAILED_DIR="/var/lib/audiobook-pipeline/failed"
PIPELINE_BIN="/opt/audiobook-pipeline/bin/audiobook-convert"
INCOMING_DIR="/mnt/media/AudioBooks/_incoming"
STABILITY_THRESHOLD=120  # seconds (2 minutes)
```

Add comment above section: "# Automation directories for Readarr webhook and cron scanner"
  </action>
  <verify>
Test queue processor:
```bash
# Create test trigger file
mkdir -p /var/lib/audiobook-pipeline/queue
cat > /var/lib/audiobook-pipeline/queue/test-trigger.json <<EOF
{
  "timestamp": "2026-02-20T10:00:00Z",
  "event_type": "Test",
  "book_paths": "/tmp/nonexistent-book"
}
EOF

# Run processor (should move to completed or failed)
bin/queue-processor.sh

# Verify file moved
ls /var/lib/audiobook-pipeline/processing/  # Should be empty
ls /var/lib/audiobook-pipeline/failed/      # Should contain test-trigger.json (path doesn't exist)

# Verify config updated
grep "QUEUE_DIR" config.env.example
grep "INCOMING_DIR" config.env.example
```
  </verify>
  <done>bin/queue-processor.sh processes trigger files atomically without race conditions, handles pipe-separated paths, moves files to completed/failed based on pipeline exit code. config.env.example contains all automation variables.</done>
</task>

</tasks>

<verification>
**Integration test (all three scripts together):**

1. Create test book in incoming directory: `mkdir -p /tmp/test-incoming/Book && touch -d "5 minutes ago" /tmp/test-incoming/Book/track01.mp3`
2. Run cron scanner: `INCOMING_DIR=/tmp/test-incoming bin/cron-scanner.sh`
3. Verify trigger created: `ls /var/lib/audiobook-pipeline/queue/*.json`
4. Run queue processor: `PIPELINE_BIN=/bin/true bin/queue-processor.sh` (use /bin/true to simulate success)
5. Verify trigger moved to completed: `ls /var/lib/audiobook-pipeline/completed/*.json`

**Readarr webhook test:**

1. Simulate Readarr Test event: `readarr_eventtype=Test bin/readarr-hook.sh && echo "Exit: $?"`
2. Simulate Download event: `readarr_eventtype=Download readarr_addedbookpaths="/test/path" bin/readarr-hook.sh`
3. Verify queue file created: `cat /var/lib/audiobook-pipeline/queue/*.json | jq .`

**No race condition test:**

1. Create trigger file
2. Run two queue processors in parallel: `bin/queue-processor.sh & bin/queue-processor.sh &`
3. Verify only one processing directory lock file exists (atomic mv prevents double processing)
</verification>

<success_criteria>
1. bin/readarr-hook.sh exits within 5 seconds for all events (measured with `time` command)
2. bin/readarr-hook.sh creates valid JSON trigger files in queue directory
3. bin/cron-scanner.sh detects new books in incoming directory and creates trigger files
4. bin/cron-scanner.sh skips books with recent mtime changes (stability check)
5. bin/cron-scanner.sh skips already-processed books (manifest exists)
6. bin/queue-processor.sh processes trigger files without race conditions (atomic mv)
7. bin/queue-processor.sh handles pipe-separated book paths correctly
8. bin/queue-processor.sh moves trigger files to completed/ on success, failed/ on error
9. config.env.example documents all automation variables with defaults
10. All scripts use `#!/usr/bin/env bash` shebang and `set -euo pipefail`
</success_criteria>

<output>
After completion, create `.planning/phases/04-automation-triggers/04-01-SUMMARY.md`
</output>
