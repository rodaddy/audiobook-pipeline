# Session 2026-02-22 -- Convert Mode with CPU-Aware Parallelism (ce5c2584)

**Session ID:** ce5c2584-153c-45d0-b4d5-dd6e798f111b
**Date:** 2026-02-22
**Branch:** feat/python-rewrite

## Summary

Implemented the full convert pipeline (validate, concat, convert stages) wrapping ffmpeg/ffprobe as subprocess calls, plus a ConvertOrchestrator for CPU-aware parallel batch processing. Fixed CPU monitoring issues (getloadavg too laggy, psutil interval=None underreporting) and dry-run flow bugs. Kicked off batch conversion of 142 books from Original/ -- currently running at ~60-70% CPU with 4 workers, 27+ books completed.

## What Was Done

1. Added `get_format_name()` to `ffprobe.py` for container format validation
2. Added `BatchResult` dataclass to `models.py`
3. Added `max_parallel_converts` and `cpu_ceiling` config fields to `config.py`
4. Created `stages/validate.py` -- discovers audio files, validates with ffprobe, natural sorts, checks disk space, detects bitrate, sums durations, writes file list
5. Created `stages/concat.py` -- generates ffmpeg concat demuxer file + FFMETADATA1 chapter file with cumulative timestamps
6. Created `stages/convert.py` -- wraps ffmpeg subprocess, auto-detects aac_at encoder, validates output codec/format/chapters
7. Updated `stages/__init__.py` -- wired VALIDATE, CONCAT, CONVERT dispatch
8. Created `convert_orchestrator.py` -- CPU-aware ThreadPoolExecutor with dynamic thread allocation per ffmpeg job
9. Updated `runner.py` -- added convert-mode batch dispatch to ConvertOrchestrator
10. Updated `stages/cleanup.py` -- extended to remove work_dir/book_hash in convert mode
11. Updated root `__init__.py` docstring
12. Created 4 test files (26 tests total) covering all new stages + orchestrator
13. Fixed dry-run flow -- work files (audio_files.txt, files.txt, metadata.txt) now always written since they're lightweight metadata needed by downstream stages
14. Fixed CPU monitoring: replaced os.getloadavg() (1-min moving avg, too laggy) with psutil.cpu_percent(interval=1.0) for accurate blocking measurement
15. Added ramp-up delay (2s sleep + 1s measurement between job submissions)
16. Lowered default max_workers from cpu_count//2 to min(4, cpu_count//3)
17. Lowered default cpu_ceiling from 85% to 80%
18. Added psutil dependency
19. Ran batch conversion on Original/ directory -- ~27+ of 142 books completed and organized to Plex library

## Files Changed

- src/audiobook_pipeline/__init__.py (docstring update)
- src/audiobook_pipeline/config.py (parallel config fields)
- src/audiobook_pipeline/ffprobe.py (get_format_name)
- src/audiobook_pipeline/models.py (BatchResult)
- src/audiobook_pipeline/runner.py (convert-mode dispatch)
- src/audiobook_pipeline/stages/__init__.py (new stage dispatch)
- src/audiobook_pipeline/stages/cleanup.py (convert mode cleanup)
- src/audiobook_pipeline/stages/validate.py (NEW)
- src/audiobook_pipeline/stages/concat.py (NEW)
- src/audiobook_pipeline/stages/convert.py (NEW)
- src/audiobook_pipeline/convert_orchestrator.py (NEW)
- tests/test_stages/test_validate.py (NEW)
- tests/test_stages/test_concat.py (NEW)
- tests/test_stages/test_convert.py (NEW)
- tests/test_convert_orchestrator.py (NEW)
- pyproject.toml (psutil dep)
- uv.lock

## Decisions Made

1. Dry-run writes work files (audio_files.txt, files.txt, metadata.txt) -- they're lightweight metadata, not the conversion itself. Only ffmpeg execution and file moves are skipped.
2. Skip organize + cleanup stages in dry-run mode (no output file to place)
3. Use psutil.cpu_percent(interval=1.0) for blocking 1s sample instead of getloadavg() or non-blocking psutil
4. Conservative auto max_workers: min(4, cpu_count//3) instead of cpu_count//2
5. CPU ceiling default 80%, configurable via CPU_CEILING env var
6. MVP stages for convert mode: VALIDATE, CONCAT, CONVERT, ORGANIZE, CLEANUP (skip ASIN, METADATA, ARCHIVE)
7. Ramp-up delay of 2s sleep + 1s measurement between job submissions to prevent burst

## Known Issues / Blockers

- Batch conversion still running (background task b3e58c2) -- ~27/142 done, need to also run NewBooks/ after Original/ finishes
- Parent directories without audio files (Andrew Rowe, (Forgotten Realms) The Sundering) fail validation -- expected behavior but could be filtered earlier
- Some books may need the organize stage to handle the converted m4b path differently if author/title parsing is tricky

## Commits This Session

- 99545f5: feat: add convert mode with CPU-aware parallel batch processing
- 4c31442: fix: use psutil for instant CPU monitoring, fix dry-run stage flow
- 5e0a0d4: fix: accurate CPU monitoring -- blocking 1s sample, conservative workers

## Next Session

### Carry-forward

- PR #5 awaiting review: https://github.com/rodaddy/audiobook-pipeline/pull/5
- Consider addressing LOW findings from adversarial review if desired (L1-L6, UI1-UI4)

### New from this session

- Run NewBooks/ batch conversion after Original/ completes
- Review failed books from both batches and fix any issues
- Consider filtering parent directories (no audio files) earlier in _find_book_directories
- Add ASIN/metadata stages for convert mode (deferred from MVP)
